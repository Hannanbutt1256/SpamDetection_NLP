{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eacbca0c",
   "metadata": {},
   "source": [
    "# Data Acquisition & Exploration\n",
    "\n",
    "First, I imported polars as replacement of pandas here just for experimenting. Then read the csv file after that removed non-essential columns. Then converted `ham` and `spam` as `0` and `1` while coverting them to `int-8`.\n",
    "After that I labeled the columns for better readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16d6d207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "818a535f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam = pl.read_csv(\n",
    "    \"C:/Users/hanna/Documents/AI projects/SpamDetection_NLP/Data/spam.csv\",\n",
    "    encoding=\"latin-1\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb4de254",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam = df_spam.select(df_spam.columns[:-3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0725e329",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam = df_spam.with_columns(\n",
    "    pl.col(\"v1\")\n",
    "      .replace({\"ham\": 0, \"spam\": 1})\n",
    "      .cast(pl.Int8)\n",
    "      .alias(\"label\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c1c5109",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam = df_spam.drop(\"v1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13409f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam = df_spam.rename({\n",
    "    \"v2\": \"text\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "718b9859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5_572, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>text</th><th>label</th></tr><tr><td>str</td><td>i8</td></tr></thead><tbody><tr><td>&quot;Go until jurong point, crazy..…</td><td>0</td></tr><tr><td>&quot;Ok lar... Joking wif u oni...&quot;</td><td>0</td></tr><tr><td>&quot;Free entry in 2 a wkly comp to…</td><td>1</td></tr><tr><td>&quot;U dun say so early hor... U c …</td><td>0</td></tr><tr><td>&quot;Nah I don&#x27;t think he goes to u…</td><td>0</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;This is the 2nd time we have t…</td><td>1</td></tr><tr><td>&quot;Will Ì_ b going to esplanade f…</td><td>0</td></tr><tr><td>&quot;Pity, * was in mood for that. …</td><td>0</td></tr><tr><td>&quot;The guy did some bitching but …</td><td>0</td></tr><tr><td>&quot;Rofl. Its true to its name&quot;</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5_572, 2)\n",
       "┌─────────────────────────────────┬───────┐\n",
       "│ text                            ┆ label │\n",
       "│ ---                             ┆ ---   │\n",
       "│ str                             ┆ i8    │\n",
       "╞═════════════════════════════════╪═══════╡\n",
       "│ Go until jurong point, crazy..… ┆ 0     │\n",
       "│ Ok lar... Joking wif u oni...   ┆ 0     │\n",
       "│ Free entry in 2 a wkly comp to… ┆ 1     │\n",
       "│ U dun say so early hor... U c … ┆ 0     │\n",
       "│ Nah I don't think he goes to u… ┆ 0     │\n",
       "│ …                               ┆ …     │\n",
       "│ This is the 2nd time we have t… ┆ 1     │\n",
       "│ Will Ì_ b going to esplanade f… ┆ 0     │\n",
       "│ Pity, * was in mood for that. … ┆ 0     │\n",
       "│ The guy did some bitching but … ┆ 0     │\n",
       "│ Rofl. Its true to its name      ┆ 0     │\n",
       "└─────────────────────────────────┴───────┘"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b953edb0",
   "metadata": {},
   "source": [
    "# Pre‑processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db2c9152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    token = word_tokenize(text)\n",
    "    token = [t for t in token if t not in stop_words]\n",
    "    token = [lemmatizer.lemmatize(t) for t in token]\n",
    "    return \" \".join(token) \n",
    "\n",
    "\n",
    "df_spam = df_spam.with_columns(\n",
    "    pl.col('text').map_elements(preprocess, return_dtype=pl.Utf8).alias('text')\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdfb4a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5_572, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>text</th><th>label</th></tr><tr><td>str</td><td>i8</td></tr></thead><tbody><tr><td>&quot;go jurong point crazy availabl…</td><td>0</td></tr><tr><td>&quot;ok lar joking wif u oni&quot;</td><td>0</td></tr><tr><td>&quot;free entry 2 wkly comp win fa …</td><td>1</td></tr><tr><td>&quot;u dun say early hor u c alread…</td><td>0</td></tr><tr><td>&quot;nah dont think go usf life aro…</td><td>0</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;2nd time tried 2 contact u u å…</td><td>1</td></tr><tr><td>&quot;ì_ b going esplanade fr home&quot;</td><td>0</td></tr><tr><td>&quot;pity mood soany suggestion&quot;</td><td>0</td></tr><tr><td>&quot;guy bitching acted like id int…</td><td>0</td></tr><tr><td>&quot;rofl true name&quot;</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5_572, 2)\n",
       "┌─────────────────────────────────┬───────┐\n",
       "│ text                            ┆ label │\n",
       "│ ---                             ┆ ---   │\n",
       "│ str                             ┆ i8    │\n",
       "╞═════════════════════════════════╪═══════╡\n",
       "│ go jurong point crazy availabl… ┆ 0     │\n",
       "│ ok lar joking wif u oni         ┆ 0     │\n",
       "│ free entry 2 wkly comp win fa … ┆ 1     │\n",
       "│ u dun say early hor u c alread… ┆ 0     │\n",
       "│ nah dont think go usf life aro… ┆ 0     │\n",
       "│ …                               ┆ …     │\n",
       "│ 2nd time tried 2 contact u u å… ┆ 1     │\n",
       "│ ì_ b going esplanade fr home    ┆ 0     │\n",
       "│ pity mood soany suggestion      ┆ 0     │\n",
       "│ guy bitching acted like id int… ┆ 0     │\n",
       "│ rofl true name                  ┆ 0     │\n",
       "└─────────────────────────────────┴───────┘"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90111b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go jurong point crazy available bugis n great world la e buffet cine got amore wat\n",
      "ok lar joking wif u oni\n",
      "free entry 2 wkly comp win fa cup final tkts 21st may 2005 text fa 87121 receive entry questionstd txt ratetcs apply 08452810075over18s\n",
      "u dun say early hor u c already say\n",
      "nah dont think go usf life around though\n",
      "freemsg hey darling 3 week word back id like fun still tb ok xxx std chgs send å150 rcv\n",
      "even brother like speak treat like aid patent\n",
      "per request melle melle oru minnaminunginte nurungu vettam set callertune caller press 9 copy friend callertune\n",
      "winner valued network customer selected receivea å900 prize reward claim call 09061701461 claim code kl341 valid 12 hour\n",
      "mobile 11 month u r entitled update latest colour mobile camera free call mobile update co free 08002986030\n"
     ]
    }
   ],
   "source": [
    "# Show first 10 rows fully\n",
    "for row in df_spam.head(10).select(\"text\").to_series():\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3868b050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f35f5519",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_spam[\"text\"]\n",
    "y = df_spam[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c40b08c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: 3900, Val: 568, Test: 1104\n"
     ]
    }
   ],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.66, random_state=42, stratify=y_temp\n",
    ")\n",
    "print(f\"\\nTrain: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "553175c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1a7031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vectorizer = CountVectorizer(ngram_range=(1,2), min_df=2)\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
    "X_val_bow = bow_vectorizer.transform(X_val)\n",
    "X_test_bow = bow_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ca8ee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df= 2)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = tfidf_vectorizer.transform(X_val)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba22aba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "word2vec_model = api.load(\"fasttext-wiki-news-subwords-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4aca288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def document_vector(doc):\n",
    "    words = doc.split()\n",
    "    vecs = [word2vec_model[w] for w in words if w in word2vec_model]\n",
    "    if len(vecs) == 0:  # fallback for empty doc\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "    return np.mean(vecs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "178b5998",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_dense = np.array([document_vector(d) for d in X_train])\n",
    "X_val_dense = np.array([document_vector(d) for d in X_val])\n",
    "X_test_dense = np.array([document_vector(d) for d in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25e8daeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def evaluate_model(model, X_tr, y_tr, X_te, y_te, description=\"Model\"):\n",
    "    model.fit(X_tr, y_tr)\n",
    "    y_pred = model.predict(X_te)\n",
    "    print(f\"\\n=== {description} ===\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_te, y_pred))\n",
    "    print(classification_report(y_te, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "701be819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Naive Bayes (BoW) ===\n",
      "Accuracy: 0.9753521126760564\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       492\n",
      "           1       0.96      0.86      0.90        76\n",
      "\n",
      "    accuracy                           0.98       568\n",
      "   macro avg       0.97      0.92      0.94       568\n",
      "weighted avg       0.98      0.98      0.97       568\n",
      "\n",
      "\n",
      "=== Naive Bayes (TF-IDF) ===\n",
      "Accuracy: 0.9559859154929577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98       492\n",
      "           1       1.00      0.67      0.80        76\n",
      "\n",
      "    accuracy                           0.96       568\n",
      "   macro avg       0.98      0.84      0.89       568\n",
      "weighted avg       0.96      0.96      0.95       568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "evaluate_model(nb_model, X_train_bow, y_train, X_val_bow, y_val, \"Naive Bayes (BoW)\")\n",
    "evaluate_model(nb_model, X_train_tfidf, y_train, X_val_tfidf, y_val, \"Naive Bayes (TF-IDF)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0b80afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression (BoW) ===\n",
      "Accuracy: 0.971830985915493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       492\n",
      "           1       1.00      0.79      0.88        76\n",
      "\n",
      "    accuracy                           0.97       568\n",
      "   macro avg       0.98      0.89      0.93       568\n",
      "weighted avg       0.97      0.97      0.97       568\n",
      "\n",
      "\n",
      "=== Logistic Regression (TF-IDF) ===\n",
      "Accuracy: 0.9665492957746479\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       492\n",
      "           1       0.98      0.76      0.86        76\n",
      "\n",
      "    accuracy                           0.97       568\n",
      "   macro avg       0.97      0.88      0.92       568\n",
      "weighted avg       0.97      0.97      0.96       568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic Regression (sparse)\n",
    "lr_model = LogisticRegression(max_iter=500)\n",
    "evaluate_model(lr_model, X_train_bow, y_train, X_val_bow, y_val, \"Logistic Regression (BoW)\")\n",
    "evaluate_model(lr_model, X_train_tfidf, y_train, X_val_tfidf, y_val, \"Logistic Regression (TF-IDF)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "882916cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression (Word2Vec) ===\n",
      "Accuracy: 0.9295774647887324\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       492\n",
      "           1       0.79      0.64      0.71        76\n",
      "\n",
      "    accuracy                           0.93       568\n",
      "   macro avg       0.87      0.81      0.84       568\n",
      "weighted avg       0.93      0.93      0.93       568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_dense_model = LogisticRegression(max_iter=500)\n",
    "evaluate_model(lr_dense_model, X_train_dense, y_train, X_val_dense, y_val, \"Logistic Regression (Word2Vec)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53e5e99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 3-gram Markov Chain Generated Text ===\n",
      "ceive å500000 easter prize drawplease telephone 09041940223 claim 290305 prize transferred someone e\n",
      "leep wish great day full feeling better opportunity last thought babe love kiss urgent ur å500 guara\n",
      "a thanks talk saturday dear cherish brother role model k im leaving soon little 9 ok anyway need cha\n",
      "e india onionrs ltgt petrolrs ltgt beerrs ltgt shesil ltgt hello yeah ive got bath need hair ill com\n",
      "axx match startedindia ltgt 2 jokin oni lar ìï busy wun disturb ì_ guy go see movie side ok come n p\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "def build_markov_chain(texts, n=3):\n",
    "    chain = defaultdict(list)\n",
    "    corpus = \" \".join(texts)\n",
    "    for i in range(len(corpus) - n):\n",
    "        ngram = corpus[i:i+n]\n",
    "        next_char = corpus[i+n]\n",
    "        chain[ngram].append(next_char)\n",
    "    return chain\n",
    "\n",
    "def generate_text(chain, length=100):\n",
    "    ngram = random.choice(list(chain.keys()))\n",
    "    result = ngram\n",
    "    for _ in range(length):\n",
    "        if ngram in chain:\n",
    "            next_char = random.choice(chain[ngram])\n",
    "            result += next_char\n",
    "            ngram = result[-len(ngram):]\n",
    "        else:\n",
    "            break\n",
    "    return result\n",
    "\n",
    "# Build chain on training data\n",
    "markov_chain = build_markov_chain(X_train, n=20)\n",
    "\n",
    "# Generate 5 sample texts\n",
    "print(\"\\n=== 3-gram Markov Chain Generated Text ===\")\n",
    "for i in range(5):\n",
    "    print(generate_text(markov_chain, length=80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29f1ea8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Naives Bayes Model with BOW ===\n",
      "Accuracy: 0.9764492753623188\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       956\n",
      "           1       0.94      0.88      0.91       148\n",
      "\n",
      "    accuracy                           0.98      1104\n",
      "   macro avg       0.96      0.94      0.95      1104\n",
      "weighted avg       0.98      0.98      0.98      1104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_bow_model = nb_model.fit(X_train_bow, y_train)\n",
    "y_pred = nb_model.predict(X_test_bow)\n",
    "print(f\"\\n=== Naives Bayes Model with BOW ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce42cffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"spam_bow_nb.pkl\", \"wb\") as f:\n",
    "    pickle.dump(nb_bow_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6045fd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bow_vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(bow_vectorizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06adcae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
